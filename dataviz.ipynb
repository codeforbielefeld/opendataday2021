{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Data, und dann? \n",
    "## Einführung in die Visualisierung von offenen Daten\n",
    "\n",
    "In unserem Projekt sensor.community messen Menschen auf der ganzen Welt mit selbst gebauten Sensoren die Luftqualität in ihrem Garten, vor ihrer Haustür, auf ihrem Balkon. In diesem interaktiven Workshop zeigen wir euch, wie die gemessenen Daten aussehen und wie ihr daraus erste Visualisierungen erstellt.\n",
    "\n",
    "Wir benutzen dafür Jupyter-Notebooks, Datensätze des Open Data Portals der Stadt Bielefeld und die Feinstaubdaten von sensor.community.\n",
    "\n",
    "Für den Workshop ist kein besonderes Vorwissen nötig, lediglich eine stabile Internetverbindung und das Interesse, ein wenig Programmiercode näher gebracht zu bekommen. Der Workshop ist also auch offen für alle Open-Data-Neulinge. \n",
    "\n",
    "***\n",
    "\n",
    "Agenda:\n",
    "\n",
    "1. Sehr kurze Einführung in Python\n",
    "2. Visualisierung eines Datensatzes des Open Data-Portals der Stadt Bielefeld\n",
    "3. Zugriff auf Daten der Feinstaubsensoren in Bielefeld\n",
    "4. Zeichnen einer interaktiven Karte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sehr kurze Einführung in Python\n",
    "Python ist eine im Data Science-Bereich sehr verbreitete Programmiersprache und bietet mit vielen Programmbibliotheken wie Numpy (Verarbeitung von Matrizen), Pandas (Verwaltung von Daten), Plotly (Datenvisualisierung) und verschiedenen Frameworks wie Flask (Webserver), Dash (Visualisierung) und Tensorflow (Machine Learning) ein großes Spektrum an frei verfügbaren und sehr gut dokumentiertem Code.  \n",
    "\n",
    "Achtung: Die Strukturierung des Codes wird nicht wie bei vielen anderen Programmiersprachen über Klammern geregelt, sondern über die Einrückungen des Codes.\n",
    "\n",
    "### Schleifen\n",
    "Mithilfe verschiedener Schleifen kann wiederholbarer Code für eine gegebene Sequenz oder eine Liste an Werten abgebildet werden.\n",
    "\n",
    "#### For-Schleife\n",
    "Zur Iteration über Listen, Squenzen oder einer Range können For-Schleifen genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While-Schleife\n",
    "Widerholung des Schleifeninhaltes solange eine Bedingung gültig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i <= 4:\n",
    "    print(i)\n",
    "    i += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If-Else-Bedingungen\n",
    "Code innerhalb der if-Bedingung wird nur ausgeführt, wenn die if-Bedingung wahr ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0, 1]:\n",
    "    if i == 1:\n",
    "        print(i, ': ', True)\n",
    "    else:\n",
    "        print(i, ': ', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktionen\n",
    "Zur besseren Strukturierung, Wiederverwendbarkeit und Lesbarkeit sollten klar abgrenzbare Codeschnipsel mit wohldefinierten Methodennamen in Funktionen gezogen werden. Eine Methode kann Übergabeparameter entgegennehmen, die innerhalb der Methode genutzt und / oder verändert werden. Gleichzeitig kann die Methode zum Schluss keinen, einen oder mehrere Werte als Rückgabeparameter über das Wort \"return\" zurückgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methode definieren\n",
    "def get_center_value(values: [int]):\n",
    "    center_index: int = int(len(values) / 2)\n",
    "    return values[center_index]\n",
    "\n",
    "# Übergabeparameter definieren\n",
    "values = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Methode aufrufen\n",
    "center_value = get_center_value(values)\n",
    "print('Center value: ', center_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "Programmierbibliothek zur Verarbeitung, Verwaltung und Analyse von Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden von CSV Dateien\n",
    "Comma-separated values(CSV) beschreibt den Aufbau einer Textdatei zur Speicherung oder zum Austausch einfach strukturierter Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = pd.read_csv('data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung eines Datensatzes des Open Data-Portals der Stadt Bielefeld\n",
    "\n",
    "Zunächst möchten wir uns Daten des Portals zur Anzeige bringen. Hierzu verwenden wir \n",
    "\n",
    "1. die Wahlergebnisse der Bundestagswahl 2017 und\n",
    "2. die demographischen Daten der Stadtbezirke."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wahlergebnisse\n",
    "Auf [dieser Webseite](https://open-data.bielefeld.de/dataset/wahlen-und-abstimmungen-bielefeld) finden sich alle Datensätze zu Wahlen und Abstimmungen der Stadt. Ganz unten auf der Seite finden sich die aktuellsten Daten, und dort sehen wir \n",
    "\n",
    "<img src=\"img/Daten_Download_1.png\" width=\"750\" height=\"250\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fahren wir nun mit dem Mauszeiger über den Button `Download`, so sehen wir die eigentliche URL des Datensatzes:\n",
    "\n",
    "<img src=\"img/Daten_Download_2.png\" width=\"900\" height=\"250\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese URL fügen wir in die Funktion zum Einlesen einer CSV-Datei ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bundestagswahl2017 = 'https://open-data.bielefeld.de/sites/default/files/BTW 2017_1.csv'\n",
    "df_btw = pd.read_csv(url_bundestagswahl2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider erhalten wir die Fehlermeldung, dass kein Leerzeichen in einer URL als Eingabe dieser Funktion vorhanden sein darf. \n",
    "\n",
    "Ersetzen wir also das Leerzeichen mit `%20`, welches wir aus reinem Zufall kennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bundestagswahl2017 = 'https://open-data.bielefeld.de/sites/default/files/BTW%202017_1.csv'\n",
    "df_btw = pd.read_csv(filepath_or_buffer=url_bundestagswahl2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein andere Fehler taucht auf. Es wird eine Encodierung angesprochen und wir haben den Verdacht, dass die CSV-Datei mithilfe von Word auf einer Windows-Maschine erstellt sein könnte. Wenn nicht explizit darauf geachtet wird, werden so leider Dateien erstellt, welche nicht ein Standard-Format besitzen.\n",
    "\n",
    "Aber wieder wissen wir uns zu helfen und tippen darauf, dass wir die Encodierung `ANSI` verwenden sollten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bundestagswahl2017 = 'https://open-data.bielefeld.de/sites/default/files/BTW%202017_1.csv'\n",
    "df_btw = pd.read_csv(filepath_or_buffer=url_bundestagswahl2017, encoding='palmos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und noch ein Fehler...\n",
    "\n",
    "Irgendetwas scheint mit der erwarteten Anzahl der Spalten nicht zu stimmen. Obwohl das Datenformat CSV (comma-separated values), wird häufig ein Semikolon anstelle eines Kommas eingesetzt. Probieren wir es also aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bundestagswahl2017 = 'https://open-data.bielefeld.de/sites/default/files/BTW%202017_1.csv'\n",
    "df_btw = pd.read_csv(filepath_or_buffer=url_bundestagswahl2017, sep=';', encoding='palmos')\n",
    "df_btw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um einen besseren Eindruck über die verfügbaren Daten zu erhalten, lassen wir uns alle Spaltennamen anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_btw.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir uns lediglich für die prozentuale Verteilung der Stimmen interessieren, so können wir die entsprechenden Spalten filtern. Leider ist im Portal nicht beschrieben, inwiefern sich die Spalten mit dem Präfix `Z_` von denjenigen ohne unterscheiden. Wir wählen diejenigen ohne Präfix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_btw_prc = [x for x in list(df_btw.keys()) if '_Proz' in x and 'Z_' not in x]\n",
    "list_btw_prc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erzeugen einen Dataframe mit nur obigen Spalten und der Wahlbezirksnummer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btw_prc = df_btw[['Nr'] + list_btw_prc].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider ist in dem Datensatz nicht ein international gültiges Nummernformat verwendet worden, sodass wir als Text erkannte Zahlen wie `2,7` in echte Zahlen wie `2.7` umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list_btw_prc:\n",
    "    if df_btw_prc[col].dtype == object:\n",
    "        df_btw_prc[col] = df_btw_prc[col].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierdurch erhalten wir folgenden Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btw_prc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Verteilung von Wahlbezirk 1.1 darzustellen, legen wir einen eigenen Datafram an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btw_1_1 = df_btw_prc[list_btw_prc].iloc[0].to_frame()\n",
    "df_btw_1_1.reset_index(inplace=True)\n",
    "df_btw_1_1 = df_btw_1_1.rename(columns = {'index':'Partei', 0:'Proz'})\n",
    "df_btw_1_1['Partei'] = df_btw_1_1['Partei'].str.replace('_Proz', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Kreisdiagramm mit der prozentualen Stimmenverteilung kann nach dieser Vorarbeit einfach dargestellt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.pie(df_btw_1_1.loc[df_btw_1_1['Proz'] > 0.02], values='Proz', names='Partei', title='Wahlbezirk 1.1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ließen sich noch eine Vielzahl an weiteren Grafiken und Statistiken bilden, allerdings warten noch andere Datensätze auf uns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographische Daten\n",
    "Nun betrachten wir die demographischen Daten der Stadt Bielefeld und verwenden hierfür die Daten [dieser Seite](https://open-data.bielefeld.de/dataset/\n",
    "demographie-und-statistische-gebietsgliederung). \n",
    "\n",
    "Die entsprechende URL erhalten wir per Mouse-Over über den Download-Button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_alter = 'https://open-data.bielefeld.de/sites/default/files/altersstruktur_halbjaehrlich2013bisEnde2020.csv'\n",
    "df_alter = pd.read_csv(filepath_or_buffer=url_alter, sep=';', encoding='palmos')\n",
    "df_alter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten wir zunächst wieder alle Spaltennamen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_alter_spaltennamen = list(df_alter.keys())\n",
    "list_alter_spaltennamen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da so lange Spaltennamen sehr unhandlich sind, weisen wir den Daten einfach neue zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_alter_neueSpaltennamen = ['jahr', 'stichtag', 'gebiet', 'gesamt', '0_1', '1_3', '3_5', '5_6', '6_10', '10_14', '14_15', '15_18', '18_21', '21_25', '25_30', '30_40', '40_45', '45_60', '60_65', '65_70', '70_75', '75_', 'durchschnittsalter']\n",
    "df_alter.columns = list_alter_neueSpaltennamen\n",
    "df_alter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Daten im Anschluss korrekt anzeigen zu lassen, müssen wir die Datumsangabe von `stichtag` in ein Datenformat übertragen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alter['stichtag'] = pd.to_datetime(df_alter['stichtag'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind wir in der Position für einen Stadtbezirk die Demographie anzuzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig__alter_mitte = px.bar(df_alter[df_alter['gebiet']=='Stadtbezirk Mitte'], x='stichtag', y='gesamt')\n",
    "fig__alter_mitte.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessant ist natürlich auch die Entwicklung in der gesamten Stadt, also binden wir alle Stadtbezirke ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig__alter = px.bar(df_alter, x='stichtag', y='gesamt', color='gebiet')\n",
    "fig__alter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, anscheinend gibt es einen Stadtbezirk, welchen es per Definition gar nicht gibt, nämlich `Bielefeld gesamt`. Das überprüfen wir, indem wir uns alle eindeutigen Werte der Spalte `gebiet` anzeigen lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alter['gebiet'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für eine korrekte Darstellung müssen wir also `Bielefeld gesamt` ausschließen und erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alter = df_alter[df_alter['gebiet']!='Bielefeld insgesamt']\n",
    "fig__alter_2 = px.bar(df_alter, x='stichtag', y='gesamt', color='gebiet')\n",
    "fig__alter_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zugriff auf Daten der Feinstaubsensoren in Bielefeld\n",
    "\n",
    "Im Rahmen von [Code for Bielefeld](https://codefor.de/bielefeld) beschäftigen wir uns unter anderem mit der Erhebung und Auswertung von Feinstaubdaten im Stadtgebiet. Wer sich einen Eindruck über die aktuell im Einsatz befindlichen Sensoren machen möchte, der kann diese auf [sensor.community](https://sensor.community/de/) nachschauen.\n",
    "\n",
    "Wer selbst Interesse hat einen Feinstaubsensor in Betrieb zu nehmen, der findet [hier](https://sensor.community/de/sensors/airrohr/) eine Anleitung oder kann sich den [NW-Beitrag](https://www.nw.de/lokal/bielefeld/mitte/22873870_Sich-einfach-mal-selbst-einen-Feinstaubsensor-bauen-und-auch-aufhaengen.html) zu unserem Familienworkshop Anfang Oktober letzten Jahres durchlesen.\n",
    "\n",
    "Die Sensoren übermitteln per WLAN die Messdaten alle 5 Minuten an die Plattform von [sensor.community](https://sensor.community/de/), welche wir im Folgenden nutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst laden wir notwendige Bibliotheken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum einen haben wir die Möglichkeit, die Daten der letzten 5 Minuten eines beliebigen Sensors per Rest-API abzufragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.sensor.community/airrohr/v1/sensor/49366/\"\n",
    "res = requests.get(url)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine zweite Möglichkeit besteht darin, bereits archivierte Daten von dem entsprechenden FTP-Server abzufragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_49366 = pd.read_csv('https://archive.sensor.community/2021-02-23/2021-02-23_sds011_sensor_49366.csv', sep=';')\n",
    "df_sensor_49366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie zuvor müssen wir für die zukünftige Nutzung den Zeitstempel konvertieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_49366['timestamp'] = pd.to_datetime(df_sensor_49366['timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "df_sensor_49366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly zur Datenvisualisierung\n",
    "\n",
    "Zur Darstellung der Messdaten verwenden wir die Bibliothek [https://plotly.com/python/](Plotly). Eine Vielzahl von Beispielen wie verschiedene Datentypen zur Anzeige gebracht werden können, sind dort zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als ersten Plot stellen wir die Daten der Spalte `P1` zum Zeitstempel dar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_sensor_49366, x='timestamp', y=\"P1\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An dieser Stelle sei erwähnt, dass die Spalte `P1` für die Feinstaubdaten des Typs `PM10` stehen, und `P2` für die des Typs `PM2.5`. Dementsprechend handelt es sich bei `P2` um die gesundheitlich schädlicheren Daten, da diese Partikel besonders fein sind und in die Lunge eindringen können.\n",
    "\n",
    "Bilden wir also `P1` und `P2` gemeinsam ab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    df_sensor_49366[['timestamp','P1','P2']], \n",
    "    x=\"timestamp\",\n",
    "    y=df_sensor_49366[['timestamp','P1','P2']].columns,\n",
    "    title='Feinstaubdaten des Sensors 49366 am 23.02.2021')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was müssen wir tun, um alle Daten seit dem Beginn von 2021 abzurufen? Nun, wir müssen wir jeden Tag die entsprechende URL generieren, die einzelnen Datensätze herunterladen und zuletzt zusammensetzen. Gehen wir es also an.\n",
    "\n",
    "Zunächst generieren wir alle Tage seit Jahresbeginn und formatieren diese entsprechend der Ziel-URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime(2021, 1, 1)\n",
    "end = datetime.today()\n",
    "list_dates = pd.date_range(start, end).tolist()\n",
    "list_dates = [x.strftime(\"%Y-%m-%d\") for x in list_dates]\n",
    "list_dates[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann erzeugen wir eine Liste mit allen URLs unter zu Hilfe nahme der obigen Datumsliste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_front = 'https://archive.sensor.community/'\n",
    "url_back = '_sds011_sensor_49366.csv'\n",
    "list_url = [url_front + x + '/' + x + url_back for x in list_dates]\n",
    "list_url[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da Daten erst mit einem Tag Versatz archiviert werden, müssen wir die letzte URL ausschließen, welche auf den heutigen Tag zugreifen würde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlich benötigen wir den Namen des Sensortypens, um die Daten aus dem Archiv laden zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensortyp des Sensors 49366 für Download URL holen\n",
    "df_sensor_type_49366 = df_sensor_49366['sensor_type']\n",
    "df_sensor_type_49366 = df_sensor_type_49366[0].lower()\n",
    "df_sensor_type_49366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Alle Sensordaten im Bereich Bielefeld runterladen\n",
    "url = 'https://data.sensor.community/airrohr/v1/filter/box=51.9,8.3,52.1,8.7'\n",
    "res = requests.get(url)\n",
    "data = json.loads(res.text)\n",
    "\n",
    "# Daten als pandas DataFrame laden\n",
    "df_sensor_bielefeld = pd.json_normalize(data)\n",
    "\n",
    "df_sensor_bielefeld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obige Schritte fassen wir in einer Funktion zusammen, sodass wir sie einfacher verwenden können:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methode, um anhand der Daten und der Sensor ID zu checken, ob der Sensor 'indoor' ist. Diese Information wird im Positivfall an die Download URL gehängt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_indoor(id: int, data: pd.DataFrame):\n",
    "    indoor = data[data['sensor.id'] == id]['location.indoor'].unique()[0]\n",
    "    if indoor == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "is_indoor(56514, df_sensor_bielefeld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_indoor(35381, df_sensor_bielefeld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_data_download_urls(id: int, dates: [str], sensor_type: str, indoor: bool):\n",
    "    url_front = 'https://archive.sensor.community/'\n",
    "    indoor_param = ''\n",
    "    if indoor:\n",
    "        indoor_param = '_indoor'\n",
    "    url_back = '_sensor_' + str(id) + indoor_param + '.csv'\n",
    "    \n",
    "    # URL Beginn für alle Daten generieren (ohne Sensortyp und Sensor ID)\n",
    "    list_url = [url_front + date + '/' + date + '_' + sensor_type + url_back for date in dates]\n",
    "    list_url.pop()\n",
    "    return list_url\n",
    "\n",
    "# Sensortyp vom Sensor \n",
    "sensor_id = 49366\n",
    "list_urls_sensor_49366 = get_sensor_data_download_urls(sensor_id, list_dates, df_sensor_type_49366, is_indoor(sensor_id, df_sensor_bielefeld))\n",
    "list_urls_sensor_49366[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_id = 56514\n",
    "list_urls_sensor_56514 = get_sensor_data_download_urls(sensor_id, list_dates, df_sensor_type_49366, is_indoor(sensor_id, df_sensor_bielefeld))\n",
    "list_urls_sensor_56514[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Anschluss verwenden wir eine `for`-Schleife um die Daten einzeln abzurufen und fügen sie im Anschluss zusammen.\n",
    "\n",
    "ACHTUNG: Durch die Masse an Daten im Archiv dauert der Download eine gewisse Zeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_sensor_49366 = list()\n",
    "for url in list_urls_sensor_49366:\n",
    "    list_df_sensor_49366.append(pd.read_csv(url, sep=';'))\n",
    "df_sensor_49366 = pd.concat(list_df_sensor_49366)\n",
    "df_sensor_49366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch diese Prozessschritte fassen wir in einer Funktion zusammen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_data_by_url(urls: [str]):\n",
    "    list_df_sensor = list()\n",
    "    for url in urls:\n",
    "        try:\n",
    "            result = pd.read_csv(url, sep=';')\n",
    "            list_df_sensor.append(result)\n",
    "        except:\n",
    "            None\n",
    "    if len(list_df_sensor) == 0:\n",
    "        return None\n",
    "    df = pd.concat(list_df_sensor)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    return df\n",
    "    \n",
    "df_sensor_49366 = get_sensor_data_by_url(list_urls_sensor_49366)\n",
    "df_sensor_49366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_49366['timestamp'] = pd.to_datetime(df_sensor_49366['timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "fig = px.line(\n",
    "    df_sensor_49366[['timestamp','P1','P2']], \n",
    "    x=\"timestamp\",\n",
    "    y=df_sensor_49366[['timestamp','P1','P2']].columns,\n",
    "    #hover_data={\"date\": \"|%B %d, %Y\"},\n",
    "    title='custom tick labels')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir holen uns alle Sensor IDs für Bielefeld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Sensor IDs für Bielfeld\n",
    "sensor_ids_bielefeld = df_sensor_bielefeld['sensor.id'].unique()\n",
    "\n",
    "sensor_ids_bielefeld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir nun wissen, wie die Daten aussehen, können wir uns eine Methode schreiben, um den Namen des Sensortypen eines Sensors holen können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Übersicht des Dataframes für Bielefeld..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_bielefeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensortyp für Sensor ID holen\n",
    "def get_sensor_type_name_by_id(id: int, data: pd.DataFrame):\n",
    "    sensor_type = data[data['sensor.id'] == id]['sensor.sensor_type.name']\n",
    "    sensor_type = sensor_type.iloc[0].lower()\n",
    "    return sensor_type\n",
    "\n",
    "get_sensor_type_name_by_id(23236, df_sensor_bielefeld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter die Sensordaten nach dem aktuellen Jahr\n",
    "df_sensor_bielefeld['timestamp'] = pd.to_datetime(df_sensor_bielefeld['timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "df_sensor_bielefeld_2021 = df_sensor_bielefeld[df_sensor_bielefeld['timestamp'].dt.year == 2021]\n",
    "df_sensor_bielefeld_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figur für einen Sensor erstellen\n",
    "\n",
    "def create_sensor_figure(data: pd.DataFrame, sensor_id: int):\n",
    "    return px.line(\n",
    "        data[['P1', 'P2', 'timestamp']], \n",
    "        x='timestamp',\n",
    "        y=data[['P1', 'P2', 'timestamp']].columns,\n",
    "        title='Luftdaten Bielefeld 2021 - ' + str(sensor_id))\n",
    "\n",
    "fig = create_sensor_figure(df_sensor_49366, 49366)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_bielefeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_sensor_bielefeld = list()\n",
    "for sensor in sensor_ids_bielefeld[:5]:\n",
    "    sensor_type = get_sensor_type_name_by_id(int(sensor), df_sensor_bielefeld)\n",
    "    download_urls = get_sensor_data_download_urls(sensor, list_dates, sensor_type, is_indoor(sensor, df_sensor_bielefeld))\n",
    "    sensor_data = get_sensor_data_by_url(download_urls)\n",
    "    list_df_sensor_bielefeld.append(sensor_data)\n",
    "\n",
    "df_sensor_bielefeld_2021 = pd.concat(list_df_sensor_bielefeld)\n",
    "df_sensor_bielefeld_2021  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entfernen der nicht validen \"nan\" Werte..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_bielefeld_2021 = df_sensor_bielefeld_2021.dropna(subset=['sensor_id', 'timestamp', 'P1', 'P2'])\n",
    "df_sensor_bielefeld_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mit P1\n",
    "fig = px.line(df_sensor_bielefeld_2021, x=\"timestamp\", y=\"P1\", color=\"sensor_id\", line_group=\"sensor_id\", hover_name=\"sensor_id\",\n",
    "        line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mit P2\n",
    "fig = px.line(df_sensor_bielefeld_2021, x=\"timestamp\", y=\"P2\", color=\"sensor_id\", line_group=\"sensor_id\", hover_name=\"sensor_id\",\n",
    "        line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse der Feinstaubveränderungen in Bielefeld zu Silvester 2019 / 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erstellen eine Liste mit den Tagen für Dezember 2019 und Januar 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime(2019, 12, 1)\n",
    "end = datetime(2020, 1, 31)\n",
    "list_dates_silvester_19_20 = pd.date_range(start, end).tolist()\n",
    "list_dates_silvester_19_20 = [x.strftime(\"%Y-%m-%d\") for x in list_dates_silvester_19_20]\n",
    "list_dates_silvester_19_20[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir nur die aktuellen Sensor IDs aus den letzten 5 Minuten ziehen können, verändern wir die get_sensor_data_by_url Methode ein wenig..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_data_by_url(urls: [str]):\n",
    "    list_df_sensor = list()\n",
    "    try:\n",
    "        for url in urls:\n",
    "            result = pd.read_csv(url, sep=';')\n",
    "            list_df_sensor.append(result)\n",
    "    except:\n",
    "        print('Sensor für gegebenen Zeitraum nicht verfügbar:', url)\n",
    "    if len(list_df_sensor) == 0:\n",
    "        return None\n",
    "    df = pd.concat(list_df_sensor)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%dT%H:%M:%S')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir holen uns die Daten für Bielefeld mithilfe dieser Datumsliste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_sensor_bielefeld_silvester_19_20 = list()\n",
    "for sensor in sensor_ids_bielefeld[10:]:\n",
    "    try:\n",
    "        sensor_type = get_sensor_type_name_by_id(int(sensor), df_sensor_bielefeld)\n",
    "        download_urls = get_sensor_data_download_urls(sensor, list_dates_silvester_19_20, sensor_type, is_indoor(sensor, df_sensor_bielefeld))\n",
    "        sensor_data = get_sensor_data_by_url(download_urls)\n",
    "        if sensor_data is not None:\n",
    "            list_df_sensor_bielefeld_silvester_19_20.append(sensor_data)\n",
    "    except:\n",
    "        None\n",
    "df_sensor_bielefeld_silvester_19_20 = pd.concat(list_df_sensor_bielefeld_silvester_19_20)\n",
    "df_sensor_bielefeld_silvester_19_20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mit P1\n",
    "fig = px.line(df_sensor_bielefeld_silvester_19_20, x=\"timestamp\", y=\"P1\", color=\"sensor_id\", line_group=\"sensor_id\", hover_name=\"sensor_id\",\n",
    "        line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mit P2\n",
    "fig = px.line(df_sensor_bielefeld_silvester_19_20, x=\"timestamp\", y=\"P2\", color=\"sensor_id\", line_group=\"sensor_id\", hover_name=\"sensor_id\",\n",
    "        line_shape=\"spline\", render_mode=\"svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeichnen einer interaktiven Karte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO-DO:\n",
    "\n",
    "- Normalisiere Zeitstempel auf 5min-Intervalle\n",
    "- Plotte Karte für je PM10 und PM2.5\n",
    "- Gib Ausblick über Weiterführung und Einladung zu Code for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_bielefeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensor_bielefeld_2021[['location.latitude', 'location.longitude', 'sensor.sensor_type.id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sensor_bielefeld_2021[['location.latitude', 'location.longitude', 'sensor.sensor_type.id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location.latitude'] = df['location.latitude'].astype(float)\n",
    "df['location.longitude'] = df['location.longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_mapbox(\n",
    "    df, \n",
    "    lat=\"location.latitude\", \n",
    "    lon=\"location.longitude\", \n",
    "    color=\"sensor.sensor_type.id\", \n",
    "    size=\"sensor.sensor_type.id\",\n",
    "    color_continuous_scale=px.colors.cyclical.IceFire, \n",
    "    size_max=15, \n",
    "    zoom=10,\n",
    "    mapbox_style=\"carto-positron\"\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
